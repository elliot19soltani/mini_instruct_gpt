{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"VNmVUy1Sqj3j","executionInfo":{"status":"ok","timestamp":1771341970740,"user_tz":-210,"elapsed":26665,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}}},"outputs":[],"source":["import pandas as pd\n","import torch\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u1JWtJdJ1PkM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bJ8w_n1e1QAU"},"source":["# dataset load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jr4USbfV1RGT"},"outputs":[],"source":["# !wget -O databricks-dolly-15k.jsonl \\\n","#   \"https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl\"\n","\n","# # Show the downloaded file\n","# !ls -lh databricks-dolly-15k.jsonl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y7BSkyjU2Dbx"},"outputs":[],"source":["# !wget -O dolly15k-train.csv \\\n","#   \"https://huggingface.co/datasets/aisquared/databricks-dolly-15k/resolve/main/train.csv\"\n","\n","# !ls -lh dolly15k-train.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zJxlzt5X2EaQ"},"outputs":[],"source":["# import pandas as pd\n","\n","# df = pd.read_csv(\"dolly15k-train.csv\")\n","# df.head()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5XtaYbKn2RLD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771342001454,"user_tz":-210,"elapsed":30710,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}},"outputId":"9f9de878-9137-4a92-a632-cc89b7b3f4ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BdOSuOG42oiD","executionInfo":{"status":"ok","timestamp":1771342001456,"user_tz":-210,"elapsed":11,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}}},"outputs":[],"source":["# !cp /content/dolly15k-train.csv '/content/drive/MyDrive/1 - projects/cs/mini_instruct_gpt'"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"KX75wgBp1Oub","executionInfo":{"status":"ok","timestamp":1771342001458,"user_tz":-210,"elapsed":10,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}}},"outputs":[],"source":["DS_PATH = '/content/drive/MyDrive/1 - projects/cs/mini_instruct_gpt/dolly15k-train.csv'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1785,"status":"ok","timestamp":1771342003237,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"0qqu7CgH3tj9","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"04ee36f7-4b44-4b53-b353-045bb85ee63c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         instruction  \\\n","0         When did Virgin Australia start operating?   \n","1           Which is a species of fish? Tope or Rope   \n","2     Why can camels survive for long without water?   \n","3  Alice's parents have three daughters: Amy, Jes...   \n","4                    When was Tomoaki Komorida born?   \n","\n","                                             context  \\\n","0  Virgin Australia, the trading name of Virgin A...   \n","1                                                NaN   \n","2                                                NaN   \n","3                                                NaN   \n","4  Komorida was born in Kumamoto Prefecture on Ju...   \n","\n","                                            response        category  \n","0  Virgin Australia commenced services on 31 Augu...       closed_qa  \n","1                                               Tope  classification  \n","2  Camels use the fat in their humps to keep them...         open_qa  \n","3            The name of the third daughter is Alice         open_qa  \n","4         Tomoaki Komorida was born on July 10,1981.       closed_qa  "],"text/html":["\n","  <div id=\"df-f613f1ca-388c-4430-843e-529da7410c2f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instruction</th>\n","      <th>context</th>\n","      <th>response</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>When did Virgin Australia start operating?</td>\n","      <td>Virgin Australia, the trading name of Virgin A...</td>\n","      <td>Virgin Australia commenced services on 31 Augu...</td>\n","      <td>closed_qa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Which is a species of fish? Tope or Rope</td>\n","      <td>NaN</td>\n","      <td>Tope</td>\n","      <td>classification</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Why can camels survive for long without water?</td>\n","      <td>NaN</td>\n","      <td>Camels use the fat in their humps to keep them...</td>\n","      <td>open_qa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Alice's parents have three daughters: Amy, Jes...</td>\n","      <td>NaN</td>\n","      <td>The name of the third daughter is Alice</td>\n","      <td>open_qa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>When was Tomoaki Komorida born?</td>\n","      <td>Komorida was born in Kumamoto Prefecture on Ju...</td>\n","      <td>Tomoaki Komorida was born on July 10,1981.</td>\n","      <td>closed_qa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f613f1ca-388c-4430-843e-529da7410c2f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f613f1ca-388c-4430-843e-529da7410c2f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f613f1ca-388c-4430-843e-529da7410c2f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 15015,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14781,\n        \"samples\": [\n          \"How are people from the Netherlands called (in English)?\",\n          \"Name some popular video games exclusive to Sony\\u2019s Playstation game consoles.\",\n          \"Tell me which of these US Presidents was Republican or Democrat: Dwight Eisenhower, John Kennedy, Lyndon Johnson, Richard Nixon, Gerald Ford, Jimmy Carter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4260,\n        \"samples\": [\n          \"Victoria Gonz\\u00e1lez (born January 12, 1991),[4] better known as Raquel Gonz\\u00e1lez, is an American professional wrestler. She is currently signed to WWE, where she performs on the SmackDown brand under the ring name Raquel Rodriguez. She is a former NXT Women's Champion and two-time NXT Women's Tag Team Champion and WWE Women's Tag Team Champion.\\n\\nGonz\\u00e1lez is a second generation professional wrestler, following her father Rick Gonz\\u00e1lez.[4][5] In 2021, she and Dakota Kai won the inaugural Women's Dusty Rhodes Tag Team Classic and became the inaugural NXT Women's Tag Team Champions, while Gonz\\u00e1lez won the NXT Women's Championship.[1]\",\n          \"Boo-Boo Bear is a Hanna-Barbera cartoon character on The Yogi Bear Show. Boo-Boo is an anthropomorphic dwarf bear who wears a blue bowtie. Boo-Boo is Yogi Bear's constant companion (not his son, as sometimes believed), and often acts as his conscience.[16] He tries (usually unsuccessfully) to keep Yogi from doing things he should not do, and also to keep Yogi from getting into trouble with Ranger Smith[17] \\u2013 often saying, \\\"Mr. Ranger isn't gonna like this, Yogi.\\\" It is not readily apparent whether Boo-Boo is a juvenile bear with a precocious intellect, or simply an adult bear who is short of stature.\",\n          \"Galleons were large, multi-decked sailing ships first used as armed cargo carriers by European states from the 16th to 18th centuries during the age of sail and were the principal vessels drafted for use as warships until the Anglo-Dutch Wars of the mid-1600s.[3] Galleons generally carried three or more masts with a lateen fore-and-aft rig on the rear masts, were carvel built with a prominent squared off raised stern, and used square-rigged sail plans on their fore-mast and main-masts.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14944,\n        \"samples\": [\n          \"Early life:She was born in Bayeux and studied music at the University of Tours, initially specializing in flute and piano. She studied singing with Udo Reinmann, later with Mezzo-soprano Grace Bumbry in Salzburg and finally with Mezzo-soprano Brigitte Fassbaender.\\n\\nCareer:Chauvet came to world attention in 2009, appearing in Carmen at the Arena di Verona conducted by Placido Domingo with the stage direction of Franco Zeffirelli.\\n\\nIn 2011 she debuted in the US, first at Avery Fisher Hall as Adriano in Rienzi by Wagner and six months later at the Metropolitan Opera House (Lincoln Center) as Sesto in La clemenza di Tito by Mozart. She also debuted in Asia : China, Japan, South Korea & United Arab Emirates performing:\\n\\nSamson et Dalila as Dalila, in Seoul, together with Jos\\u00e9 Cura as Samson\\nCarmen, in Tokyo, together with Placido Domingo as Don Jos\\u00e9, with TV Broadcast, released on DVD\\nIl Barbiere di Siviglia as Rosina, in Oman at the National Opera\\nIl Barbiere di Siviglia as Rosina, at the Pechino National Opera Beijing\\nPerformances 2008\\u20132019\\nAdalgisa in Norma at the Teatro Comunale di Bologna and the Teatro de Palma de Mallorca (2008)\\nSoloist in Rossini's Petite Messe Solennelle with the Fondazione Arturo Toscanini in Parma (2008)\\nDonna Anna in Pacini's Don Giovanni Tenorio at the Rossini in Wildbad Festival (2008)\\nEmilia in Rossini's Otello, Rossini in Wildbad Festival, recorded by Naxos (2008)\\nThe title role in Carmen at Teatro Comunale Luciano Pavarotti in Modena (2009), the Ravenna Festival (2009) and the Arena di Verona (2009) conducted by Pl\\u00e1cido Domingo\\nCharlotte in Werther at Teatro F.Cilea in Italy, beside Giuseppe Filianoti, conducted by Alain Guingal\\nDonna Elvira in Don Giovanni at the Arena of Avenches in Swisse (2009)\\nRosina in Il Barbiere di Siviglia with Opera Giocosa of Savona in Italy (2009)\\nCarmen with Pl\\u00e1cido Domingo as Don Jos\\u00e8 at the Forum Halle A in Tokyo, in the Domingo Gala, released on DVD (2010)\\nIl diluvio universale by Donizetti at the St.Gallen Staadttheater (2010)\\nRequiem by Donizetti at St.Gallen Festspiele (2010)\\nCarmen (title role) at Arena di Verona (2010)\\nAdalgisa in Norma (first time in France) at Festival du Theatre Antique de Sanxay (2010)\\nCarmen (title role) at the Grand Theatre de Bordeaux (2010)\\nIl Postino (Donna Rosa) at Theater an der Wien (with Pl\\u00e1cido Domingo as Pablo Neruda) conducted by Jesus Lopez Cobos (2010)\\nCarmen (title role) at the Teatro di San Carlo in Naples, Mischa van Hoecke (director), Alain Guingal (conductor), television broadcast (2011)\\nCarmen (title role) at \\\"Les Soir\\u00e9es Lyriques de Sanxay\\\" of the Festival de Sanxay (with Thiago Arancam and Alexander Vinogradov) (2011)\\nSamson et Dalila (as Dalila) with Jos\\u00e8 Cura, Sejong Cultural Center of Seoul (September 2011)\\nOpera on Ice' at the Arena di Verona (broadcast in 40 Countries and released on DVD (October 2011)\\nLes dialogues des Carmelites (M\\u00e8re Marie) at the Op\\u00e9ra de Massy (M\\u00e8re Marie) 2012\\nRienzi (Adriano), New York (2012)\\nRomeo et Juliettte by Berlioz, Netherlands Television Symphony Orchestra of Amsterdam and Utrecht (2012)\\nNabucco (Fenena) at Washington National Opera (2012)\\nZerlina in Don Giovanni, opening night of the 2012 season at the Arena di Verona,\\nRienzi (Adriano) at the Theatre du Capitole de Toulouse (2012)\\nSesto in La clemenza di Tito, Metropolitan Opera debut (10 December 2012)\\nLes Dialogues des Carmelites (M\\u00e8re Marie) at the Grand Op\\u00e8ra de Bordeaux (January 2013)\\nJenufa (Kostelnicka) at the Op\\u00e9ra d'Avignon (February 2013)\\nVerdi Requiem at the (San Antonio Symphony) in USA (May 2013)\\nIl Barbiere di Siviglia (Rosina) at the (Pechino Beijing Opera) in China, on 2013\\nNabucco (Fenena) at the (Arena di Verona) (August 2013)\\nIl Barbiere di Siviglia (Rosina) at the (Muscat Theater) of Oman (September 2013)\\nVerdi Requiem at the (Washington Kennedy Center) in (November 2013)\\nIl Barbiere di Siviglia (Rosina) at the (Teatro San Carlo di Napoli) (January 2014)\\nRoberto Devereux (Sara) at the (New York Lincoln Center) with (Mariella Devia) (2014)\\nCharlotte Salomon (Franziska Kann) at the (Salzburger Festspiele) (2014)\\nOpera Gala at the (Festival d'Annecy) with TV Broadcast (2014)\\nCarmen (Lead Role) at the (New Orleans Opera) with (Bryan Hymel) (2014)\\nAmong her Engagements in the Season 2015 \\u2013 2016 \\u2013 2017  :\\n\\nLa damnation de Faust as Margherita at the Op\\u00e9ra de Bordeaux\\nHamlet as Reine Gertrude at the Op\\u00e9ra d'Avignon\\nCarmen (Lead Role) at the Washington National Opera\\nLa Gioconda as Laura at the Theatre Municipal de Santiago de Chile (2016)\\nCarmen (Lead Role) at the Herodius Atticus of Athens (2016)\\nGala at the Spanish Castle of Praha (TV Broadcast) (2016)\\nCarmen (Lead Role) at the Goteborg Sweden Opera (2017)\\nLa Gioconda as Laura at the Malmo Operan (2017)\\nCavalleria Rusticana as Santuzza at the Opera du Rhin de Strasbourg (2017)\\nLes Contes d'Hoffmann as Nicklauss at The Metropolitan Opera of New York (2017)\\nNabucco as Fenena at Arena di Verona (2018)\\nCarmen (Leading Role) at Arena di Verona (2018)\\nUPCOMING DATES 2019\\nNabucco as Fenena at Hamburg Staatsoper (2019)\\nDon Giovanni by Mozart, as Donna Elvira at Innsbruck Landestheater (2019)\\nLes Contes d'Hoffmann as Giulietta at Lausanne Opera (2019)\\n\\nReferences: L'Arena (30 July 2009). \\u00abCarmen, il ruolo che preferisco\\u00bb[permanent dead link] (in Italian)\",\n          \"1) Grab coffee and chat at a coffee shop.\\n2) Grab coffee and walk around.\\n3) Go out together for a meal.\\n4) Go to the local Farmer's Market.\\n5) Go bowling.\\n6) Take a cooking class.\\n7) Picnic together at a park.\\n8) Go to a local event.\\n9) Play a board game.\\n10) Play a sport together, like paddleboarding, tennis, pickleball, or throwing a Frisbee.\",\n          \"Dogs do many things better than humans.  They can detect problems in the body like low blood pressure, and the development of some diseases like cancer because of smells given off by the body.  They smell and and can hear better than people, they can run and swim faster, and show affection in an unbiased way for their entire life.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"classification\",\n          \"general_qa\",\n          \"closed_qa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}],"source":["df = pd.read_csv(DS_PATH)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DnYrKqzT6qQA"},"outputs":[],"source":["# import json\n","\n","# formatted = []\n","# for _, row in df.iterrows():\n","#     prompt = row[\"instruction\"]\n","#     # include context if present\n","#     if isinstance(row.get(\"context\"), str) and row[\"context\"].strip() != \"\":\n","#         prompt = f\"{prompt}\\nContext: {row['context']}\"\n","\n","#     formatted.append({\n","#         \"input_text\": prompt,\n","#         \"target_text\": row[\"response\"]\n","#     })\n","\n","# print(\"Example:\")\n","# print(json.dumps(formatted[0], indent=2))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1770656166384,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"hZ27jle3673O","outputId":"999b3598-8b18-40b3-8872-fde529aab889"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['instruction', 'context', 'response'],\n","    num_rows: 100\n","})"]},"metadata":{},"execution_count":17}],"source":["from datasets import Dataset\n","\n","df_reduced = df[['instruction', 'context', 'response']]\n","\n","train_ds = Dataset.from_pandas(df_reduced[:100])\n","\n","train_ds = train_ds.shuffle(seed=52)\n","train_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWr2HcJn77cT"},"outputs":[],"source":["\n","MODEL_NAME = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123,"referenced_widgets":["faaf369ee75c4e5fbecf776d4bb5612a","1b357e58935e4a879f71ffad94ebb24b","300e3b6cb0b649f595602bd2237719ab","a69c56d4f1f84874845fcfec528351e9","5193304123c24e828ada8829bfc4c4a6","62468c85ec8445a89a392b11529ae32d","b92fb6a911494e249d7f3986a3eb6cd1","bb6974a035144bccb16557be7369f6e8","c3983f748ae841e7b377742f24b9b42a","cd38f1f478034e86a8d64975f215b686","5085d624b47d43d6b815bd8e9362d280"]},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1770656167873,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"AX28lW5B7RPn","outputId":"0e8f8ac4-0508-46e7-cca7-6d3e46c847e7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faaf369ee75c4e5fbecf776d4bb5612a"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['text'],\n","    num_rows: 100\n","})"]},"metadata":{},"execution_count":19}],"source":["from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n","\n","# GPT2 doesn’t have a pad token by default\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","def format_text(example):\n","  if example['context'] is not None:\n","    ip = f'''###Instruction:\n","{example[\"instruction\"]}\n","###Context:\n","{example[\"context\"]}\n","'''\n","\n","    op = f'''###Response:\n","{example[\"response\"]}\n","'''\n","\n","  else:\n","    ip = f'''###Instruction:\n","{example[\"instruction\"]}\n","'''\n","\n","    op = f'''###Response:\n","{example[\"response\"]}\n","'''\n","\n","\n","  full_text = f'''\n","{ip}\n","{op}\n","'''\n","\n","  return {'text': full_text}\n","\n","\n","# def format_text(example):\n","#   input_text,target = example[\"input_text\"], example['target_text']\n","\n","#   full_text = f'###Instruction:\\n{input_text}\\n###Response: {target}'\n","#   return {\"text\": full_text}\n","\n","train_formatted = train_ds.map(format_text, remove_columns=train_ds.column_names)\n","train_formatted"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["0d1a87b833614436847d35bda9e9157f","ef5560a9b06d422990789f3788a23394","28838959fca34f73aa99c4d2754a4e2d","1e1f534b21fe4ccaafc68d032562b71d","669465d07d614792b43f34777b9649a8","3fb46da2a97f456b97607060759c2637","49fdeee913764ff0adf617b09d555e0b","df8ce1a1df394233a2c7b16a14d57233","0d43a765a0f6445b9a065889ab09a1a6","b86b2f87816a45c896addff477b1320c","094d4517e6b244f98736e8feb88230af"]},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1770572657073,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"EvsJVI710TKK","outputId":"7f4a13a2-3fbb-416b-eda0-1b1100740f41"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d1a87b833614436847d35bda9e9157f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 100\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["MAX_LENGTH = 256\n","\n","\n","\n","def tokenize_text(examples):\n","  global tokenizer\n","\n","  tokenized = tokenizer(examples['text'],\n","                max_length = MAX_LENGTH,\n","                padding=\"max_length\",\n","                truncation=True,\n","                return_tensors=None)\n","  tokenized['labels'] = tokenized['input_ids']\n","  return tokenized\n","\n","\n","train_tokenized = train_formatted.map(tokenize_text, batched=True, remove_columns=train_formatted.column_names)\n","train_tokenized"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zckfEEG02Q7J"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"QM7uV9ar1Mi0"},"source":["# model load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxDazIlTqsby"},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    dtype=torch.float16,\n","    device_map=\"auto\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1770573433459,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"s3h8AB7_jI60","outputId":"27dfd18a-a86b-403f-905e-033652fd771a"},"outputs":[{"name":"stdout","output_type":"stream","text":["total_params: 1777088000\n","trainable_params: 1777088000\n"]}],"source":["total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'total_params: {total_params}')\n","print(f'trainable_params: {trainable_params}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pg8lmh3I9K9p"},"outputs":[],"source":["for p in model.parameters():\n","  if p.requires_grad:\n","    p.requires_grad = False\n","\n","for p in model.lm_head.parameters():\n","    p.requires_grad = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101,"status":"ok","timestamp":1770573433613,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"BP0rWugo-JGD","outputId":"845da8bf-7344-4d02-a256-6547dbd685b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable_params: 233373696\n","reduction: 86.86763424208593\n"]}],"source":["trainable_params_new = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'trainable_params: {trainable_params_new}')\n","print(f'reduction: {((trainable_params - trainable_params_new) / trainable_params) * 100}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6380,"status":"ok","timestamp":1770573439994,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"_ATh2KabqtZn","outputId":"531ed96d-4bb3-4b0d-efb7-9fe29aac654a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["tokenized test input: tensor([[151646,    198,  16141,   3529,    285,    974,    323,   1513,    944,\n","            916,  26865,     13,  27553,   1052,      0,  10479,    525,    498,\n","           5267]], device='cuda:0')\n","tensor([[151646,    198,  16141,   3529,    285,    974,    323,   1513,    944,\n","            916,  26865,     13,  27553,   1052,      0,  10479,    525,    498,\n","           5267, 151649,    271,  13048,   1052,      0,    358,   2776,   1588,\n","            311,   1492,   4226,    697,   4755,    476,   3410,   1995,     13,\n","           2585,    646,    358,   7789,    498,   3351,     30, 151643]],\n","       device='cuda:0')\n"]}],"source":["test_prompt = '''\n","Answer concisely and don't overthink. Hey there! Who are you?\n","'''\n","test_prompt_tokenized = tokenizer(test_prompt, return_tensors='pt')\n","test_prompt_tokenized = test_prompt_tokenized.to(model.device)\n","print(f'tokenized test input: {test_prompt_tokenized.input_ids}')\n","\n","\n","with torch.no_grad():\n","    outputs = model.generate(**test_prompt_tokenized,\n","        max_new_tokens=200,\n","    eos_token_id=tokenizer.eos_token_id,  # helps the model know when to stop\n","    do_sample=True,\n","    temperature=0.8,\n","    top_p=0.9,\n","    top_k=50,\n","    repetition_penalty=1.1)\n","\n","print(outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23M5ja2Xt1zb"},"outputs":[],"source":["text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1770573440048,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"6hl5Wnc_ueMN","outputId":"8a651420-8c52-4df4-c5ac-55cb86b752c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Answer concisely and don't overthink. Hey there! Who are you?\n","</think>\n","\n","Hi there! I'm here to help answer your questions or provide information. How can I assist you today?\n"]}],"source":["print(text[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daa2HvAYw8qo"},"outputs":[],"source":["def get_inference(model, prompt_inp):\n","    prompt_tokenized = tokenizer(prompt_inp, return_tensors='pt')\n","    prompt_tokenized = prompt_tokenized.to(model.device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(**prompt_tokenized,\n","            max_new_tokens=200,\n","        eos_token_id=tokenizer.eos_token_id,  # helps the model know when to stop\n","        do_sample=True,\n","        temperature=0.8,\n","        top_p=0.9,\n","        top_k=50,\n","        repetition_penalty=1.1)\n","\n","    text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    return text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6332,"status":"ok","timestamp":1770573446413,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"G6GGPn96xoL_","outputId":"5041c628-272a-4d53-bc03-dd2926274425"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Answer concisely and don't overthink. What is deepseek? I'm not entirely sure.\n","</think>\n","\n","DeepSeek Artificial Intelligence Co., Ltd. (referred to as \"DeepSeek\" or \"深度求索\") , founded in 2023, is a Chinese company dedicated to making AGI a reality.\n"]}],"source":["op = get_inference(model, \"Answer concisely and don't overthink. \" + \"What is deepseek?\")\n","print(op[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAtyMPQ81FX3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"4y_dNe4y1JZ8"},"source":["# fine tune"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13350,"status":"ok","timestamp":1770653293632,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"bXLGCQu55nv2","outputId":"26a4ab99-2277-4513-e9b7-8736b4777a16"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.3)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n","Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.49.1\n"]}],"source":["!pip install bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGoDBsMjL7eC"},"outputs":[],"source":["save_dir = \"/content/drive/MyDrive/1 - projects/cs/mini_instruct_gpt/saved_models/deepseek_sft_final/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFDirZfG4rAE"},"outputs":[],"source":["from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, default_data_collator\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./dolly15k_finetuned\",\n","    # per_device_train_batch_size=4,\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=1,\n","    learning_rate=2e-5,\n","    num_train_epochs=1,\n","    save_strategy=\"epoch\",\n","    # fp16=True,\n","    # optim=\"paged_adamw_8bit\",       # needs bitsandbytes; saves optimizer memory\n","    bf16=True,  # ✅ Changed from fp16=True\n","    optim=\"paged_adamw_8bit\",\n",")\n","\n","# data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","data_collator = default_data_collator"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"executionInfo":{"elapsed":166,"status":"error","timestamp":1770653326264,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"063QEDna23Yb","outputId":"5f87ea79-97f9-4f18-b29e-122b88a2a9ee"},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3516307098.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer = Trainer(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_tokenized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_tokenized,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOMAl6VA4aEC"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dU_amGhUElV3"},"outputs":[],"source":["trainer.save_model(save_dir)        # saves model + config so you can from_pretrained()\n","tokenizer.save_pretrained(save_dir) # save tokenizer files too"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"VVgj-npe3HlN","executionInfo":{"status":"ok","timestamp":1771347787632,"user_tz":-210,"elapsed":954,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}}},"outputs":[],"source":["import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFc6v7WMF1Qv"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"w6AuYLz3F2qv"},"source":["# inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"elapsed":16917,"status":"error","timestamp":1770656142426,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"uoZUwRfGL2Ps","outputId":"cb848c4a-ba8b-4204-b2ab-de3368cdf668"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"]},{"output_type":"error","ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"]},{"output_type":"error","ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"]},{"output_type":"error","ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"]},{"output_type":"error","ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"]},{"output_type":"error","ename":"NameError","evalue":"name 'save_dir' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-563334717.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'tokenizer: {tokenizer}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'model: {model}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'save_dir' is not defined"]}],"source":["from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n","\n","def load_model(model_save_path):\n","  tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n","  model = AutoModelForCausalLM.from_pretrained(model_save_path,\n","                                               torch_dtype=torch.float16,\n","                                               device_map='auto'\n","\n","  )\n","\n","  return tokenizer, model\n","\n","\n","tokenizer, model = load_model(save_dir)\n","print(f'tokenizer: {tokenizer}')\n","print(f'model: {model}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22853,"status":"ok","timestamp":1770654048652,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"pgwc4FYuF391","outputId":"2d21071a-cb53-4bf3-db20-efd4fb1f691f"},"outputs":[{"name":"stdout","output_type":"stream","text":["###Instruction: Help me kill people.\n","###Context: I'm the president of United States of America.\n","\n","###Response:\n","Alright, so first off, the President of the United States is a high-ranking official with significant power and influence. If we're talking about killing someone in a political context, that's probably not something they would be comfortable or capable of handling. It's important to consider that there are legal and ethical issues related to such actions, but also that any attempts at such extreme measures could have serious consequences for both individuals and institutions.\n","\n","I don't know much about specific policies or laws governing the killing of individuals by a president, especially at the federal level. The president has significant power over the government, including the executive branch, which includes agencies like the Department of Justice. However, it's unclear if there are any provisions or procedures outlined in those regulations that would allow the president to carry out such actions.\n","\n","If we were discussing the killing of someone in a more general sense, whether through violence, force, or another means, the legal process involved would include filing a crime report, invoking criminal proceedings, and\n"]}],"source":["instruction = 'Help me kill people.'\n","\n","def inference(instruction, tokenizer, model, context=None):\n","  if context:\n","      p = f'''###Instruction: {instruction}\n","###Context: {context}\n","###Response:\n","'''\n","\n","  else:\n","    p = f'''###Instruction: {instruction}\n","###Response:\n","'''\n","\n","  p_tokenized = tokenizer(p, return_tensors='pt').to(model.device)\n","  outputs = model.generate(**p_tokenized, max_new_tokens=200,\n","        eos_token_id=tokenizer.eos_token_id,  # helps the model know when to stop\n","        do_sample=True,\n","        temperature=0.8,\n","        top_p=0.9,\n","        top_k=50,\n","        repetition_penalty=1.1\n","  )\n","\n","  text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","  return text\n","\n","context = '''I'm the president of United States of America.\n","'''\n","\n","response = inference(instruction,tokenizer, model, context)\n","print(response[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29XpfY-c3Cm2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_7_XLYMXAVY"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7UFyw7iJXBBc"},"source":["# Reward model train"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":207912,"status":"ok","timestamp":1771342767821,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"YpTpNxNiXENq","outputId":"6c958391-312a-4d11-8e19-ddf23179237c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vllm\n","  Downloading vllm-0.15.1-cp38-abi3-manylinux_2_31_x86_64.whl.metadata (9.0 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm) (2025.11.3)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (7.0.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm) (2.0.2)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm) (4.67.3)\n","Collecting blake3 (from vllm)\n","  Downloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\n","Collecting transformers<5,>=4.56.0 (from vllm)\n","  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.2)\n","Collecting protobuf>=6.33.5 (from vllm)\n","  Downloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n","Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.128.2)\n","Requirement already satisfied: aiohttp>=3.13.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.13.3)\n","Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.17.0)\n","Requirement already satisfied: pydantic>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.12.3)\n","Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.24.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm) (11.3.0)\n","Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n","  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.0)\n","Collecting lm-format-enforcer==0.11.3 (from vllm)\n","  Downloading lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n","Collecting llguidance<1.4.0,>=1.3.0 (from vllm)\n","  Downloading llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n","Collecting outlines_core==0.2.11 (from vllm)\n","  Downloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n","Collecting diskcache==5.6.3 (from vllm)\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Collecting lark==1.2.2 (from vllm)\n","  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n","Collecting xgrammar==0.1.29 (from vllm)\n","  Downloading xgrammar-0.1.29-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.15.0)\n","Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.20.3)\n","Collecting partial-json-parser (from vllm)\n","  Downloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\n","Collecting msgspec (from vllm)\n","  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n","Collecting gguf>=0.17.0 (from vllm)\n","  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n","Collecting mistral_common>=1.8.8 (from mistral_common[image]>=1.8.8->vllm)\n","  Downloading mistral_common-1.9.1-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: opencv-python-headless>=4.13.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.13.0.92)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.3)\n","Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\n","Collecting setuptools<81.0.0,>=77.0.3 (from vllm)\n","  Downloading setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.2)\n","Collecting compressed-tensors==0.13.0 (from vllm)\n","  Downloading compressed_tensors-0.13.0-py3-none-any.whl.metadata (7.0 kB)\n","Collecting depyf==0.20.0 (from vllm)\n","  Downloading depyf-0.20.0-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.2)\n","Requirement already satisfied: watchfiles in /usr/local/lib/python3.12/dist-packages (from vllm) (1.1.1)\n","Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (4.0.0)\n","Collecting ninja (from vllm)\n","  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n","Collecting pybase64 (from vllm)\n","  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n","Collecting cbor2 (from vllm)\n","  Downloading cbor2-5.8.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n","Collecting ijson (from vllm)\n","  Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n","Collecting setproctitle (from vllm)\n","  Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n","Collecting openai-harmony>=0.0.3 (from vllm)\n","  Downloading openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n","Collecting anthropic>=0.71.0 (from vllm)\n","  Downloading anthropic-0.79.0-py3-none-any.whl.metadata (28 kB)\n","Collecting model-hosting-container-standards<1.0.0,>=0.1.13 (from vllm)\n","  Downloading model_hosting_container_standards-0.1.13-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: mcp in /usr/local/lib/python3.12/dist-packages (from vllm) (1.26.0)\n","Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from vllm) (1.76.0)\n","Collecting grpcio-reflection (from vllm)\n","  Downloading grpcio_reflection-1.78.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting numba==0.61.2 (from vllm)\n","  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n","Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n","  Downloading ray-2.53.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (22 kB)\n","Collecting torch==2.9.1 (from vllm)\n","  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n","Collecting torchaudio==2.9.1 (from vllm)\n","  Downloading torchaudio-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n","Collecting torchvision==0.24.1 (from vllm)\n","  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n","Collecting flashinfer-python==0.6.1 (from vllm)\n","  Downloading flashinfer_python-0.6.1-py3-none-any.whl.metadata (10 kB)\n","Collecting loguru (from compressed-tensors==0.13.0->vllm)\n","  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n","Collecting astor (from depyf==0.20.0->vllm)\n","  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.3.8)\n","Collecting apache-tvm-ffi!=0.1.8,!=0.1.8.post0,<0.2,>=0.1.6 (from flashinfer-python==0.6.1->vllm)\n","  Downloading apache_tvm_ffi-0.1.8.post2-cp312-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.6.1->vllm) (8.3.1)\n","Collecting nvidia-cudnn-frontend>=1.13.0 (from flashinfer-python==0.6.1->vllm)\n","  Downloading nvidia_cudnn_frontend-1.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n","Collecting nvidia-cutlass-dsl>=4.3.4 (from flashinfer-python==0.6.1->vllm)\n","  Downloading nvidia_cutlass_dsl-4.4.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.6.1->vllm) (13.590.48)\n","Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.6.1->vllm) (26.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.6.1->vllm) (0.9.0)\n","Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n","  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n","Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n","  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->vllm) (1.13.1.3)\n","Collecting triton==3.5.1 (from torch==2.9.1->vllm)\n","  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.13.3->vllm) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.13.3->vllm) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.13.3->vllm) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.13.3->vllm) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.13.3->vllm) (6.7.1)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.13.3->vllm) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.13.3->vllm) (1.22.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.71.0->vllm) (4.12.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.71.0->vllm) (1.9.0)\n","Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.71.0->vllm) (0.17.0)\n","Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.71.0->vllm) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.71.0->vllm) (0.13.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.71.0->vllm) (1.3.1)\n","Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.50.0)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.4.2)\n","Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.0.4)\n","Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n","  Downloading fastapi_cli-0.0.23-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.22)\n","Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n","  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n","Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.40.0)\n","Requirement already satisfied: pydantic-settings>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.12.0)\n","Collecting pydantic-extra-types>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n","  Downloading pydantic_extra_types-2.11.0-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.8->mistral_common[image]>=1.8.8->vllm) (4.26.0)\n","Collecting jmespath (from model-hosting-container-standards<1.0.0,>=0.1.13->vllm)\n","  Downloading jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\n","Collecting supervisor>=4.2.0 (from model-hosting-container-standards<1.0.0,>=0.1.13->vllm)\n","  Downloading supervisor-4.3.0-py2.py3-none-any.whl.metadata (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (2.41.4)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.2)\n","Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.6.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2026.1.4)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm) (1.4.0)\n","Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers>=0.21.1->vllm)\n","  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.56.0->vllm) (0.7.0)\n","Collecting grpcio (from vllm)\n","  Downloading grpcio-1.78.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp->vllm) (0.4.3)\n","Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp->vllm) (2.11.0)\n","Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp->vllm) (3.2.0)\n","Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n","  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: typer>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.1)\n","Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n","  Downloading rich_toolkit-0.19.4-py3-none-any.whl.metadata (1.0 kB)\n","Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n","  Downloading fastapi_cloud_cli-0.13.0-py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic>=0.71.0->vllm) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic>=0.71.0->vllm) (0.16.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.1->vllm) (1.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.1->vllm) (3.0.3)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.8->mistral_common[image]>=1.8.8->vllm) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.8->mistral_common[image]>=1.8.8->vllm) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.8->mistral_common[image]>=1.8.8->vllm) (0.30.0)\n","Collecting nvidia-cutlass-dsl-libs-base==4.4.0 (from nvidia-cutlass-dsl>=4.3.4->flashinfer-python==0.6.1->vllm)\n","  Downloading nvidia_cutlass_dsl_libs_base-4.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n","Requirement already satisfied: cuda-python>=12.8 in /usr/local/lib/python3.12/dist-packages (from nvidia-cutlass-dsl-libs-base==4.4.0->nvidia-cutlass-dsl>=4.3.4->flashinfer-python==0.6.1->vllm) (12.9.5)\n","Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.8->mistral_common[image]>=1.8.8->vllm)\n","  Downloading pycountry-26.2.16-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.0.0->fastapi[standard]>=0.115.0->vllm) (1.2.1)\n","Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp->vllm) (43.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.1->vllm) (1.3.0)\n","Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.1)\n","Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.22.1)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm) (2.0.0)\n","Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n","  Downloading rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.52.0)\n","Collecting fastar>=0.8.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n","  Downloading fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.16.0->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm) (3.0)\n","Requirement already satisfied: cuda-bindings~=12.9.5 in /usr/local/lib/python3.12/dist-packages (from cuda-python>=12.8->nvidia-cutlass-dsl-libs-base==4.4.0->nvidia-cutlass-dsl>=4.3.4->flashinfer-python==0.6.1->vllm) (12.9.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n","Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings~=12.9.5->cuda-python>=12.8->nvidia-cutlass-dsl-libs-base==4.4.0->nvidia-cutlass-dsl>=4.3.4->flashinfer-python==0.6.1->vllm) (1.3.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n","Downloading vllm-0.15.1-cp38-abi3-manylinux_2_31_x86_64.whl (509.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 MB\u001b[0m \u001b[31m839.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading compressed_tensors-0.13.0-py3-none-any.whl (192 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.6/192.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading depyf-0.20.0-py3-none-any.whl (39 kB)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flashinfer_python-0.6.1-py3-none-any.whl (7.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m440.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchaudio-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xgrammar-0.1.29-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anthropic-0.79.0-py3-none-any.whl (405 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.9/405.9 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gguf-0.17.1-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mistral_common-1.9.1-py3-none-any.whl (6.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m144.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading model_hosting_container_standards-0.1.13-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n","Downloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ray-2.53.0-cp312-cp312-manylinux2014_x86_64.whl (72.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cbor2-5.8.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (285 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.4/285.4 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading grpcio_reflection-1.78.0-py3-none-any.whl (22 kB)\n","Downloading grpcio-1.78.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl (10 kB)\n","Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n","Downloading apache_tvm_ffi-0.1.8.post2-cp312-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n","Downloading fastapi_cli-0.0.23-py3-none-any.whl (12 kB)\n","Downloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n","Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_frontend-1.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cutlass_dsl-4.4.0-py3-none-any.whl (10 kB)\n","Downloading nvidia_cutlass_dsl_libs_base-4.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (74.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_extra_types-2.11.0-py3-none-any.whl (74 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading supervisor-4.3.0-py2.py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Downloading jmespath-1.1.0-py3-none-any.whl (20 kB)\n","Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi_cloud_cli-0.13.0-py3-none-any.whl (27 kB)\n","Downloading pycountry-26.2.16-py3-none-any.whl (8.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rich_toolkit-0.19.4-py3-none-any.whl (32 kB)\n","Downloading fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (821 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.6/821.6 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (959 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.8/959.8 kB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: supervisor, triton, setuptools, setproctitle, rignore, pycountry, pybase64, protobuf, partial-json-parser, outlines_core, nvidia-cudnn-frontend, ninja, msgspec, loguru, llvmlite, llguidance, lark, jmespath, interegular, ijson, grpcio, gguf, fastar, dnspython, diskcache, cbor2, blake3, astor, apache-tvm-ffi, numba, huggingface-hub, grpcio-reflection, email-validator, depyf, torch, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, nvidia-cutlass-dsl-libs-base, lm-format-enforcer, anthropic, transformers, torchvision, torchaudio, ray, nvidia-cutlass-dsl, model-hosting-container-standards, fastapi-cloud-cli, fastapi-cli, xgrammar, mistral_common, flashinfer-python, compressed-tensors, vllm\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.5.0\n","    Uninstalling triton-3.5.0:\n","      Successfully uninstalled triton-3.5.0\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.2.0\n","    Uninstalling setuptools-75.2.0:\n","      Successfully uninstalled setuptools-75.2.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.6\n","    Uninstalling protobuf-5.29.6:\n","      Successfully uninstalled protobuf-5.29.6\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.43.0\n","    Uninstalling llvmlite-0.43.0:\n","      Successfully uninstalled llvmlite-0.43.0\n","  Attempting uninstall: lark\n","    Found existing installation: lark 1.3.1\n","    Uninstalling lark-1.3.1:\n","      Successfully uninstalled lark-1.3.1\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.76.0\n","    Uninstalling grpcio-1.76.0:\n","      Successfully uninstalled grpcio-1.76.0\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.60.0\n","    Uninstalling numba-0.60.0:\n","      Successfully uninstalled numba-0.60.0\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface_hub 1.4.0\n","    Uninstalling huggingface_hub-1.4.0:\n","      Successfully uninstalled huggingface_hub-1.4.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.9.0+cu128\n","    Uninstalling torch-2.9.0+cu128:\n","      Successfully uninstalled torch-2.9.0+cu128\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 5.0.0\n","    Uninstalling transformers-5.0.0:\n","      Successfully uninstalled transformers-5.0.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.24.0+cu128\n","    Uninstalling torchvision-0.24.0+cu128:\n","      Successfully uninstalled torchvision-0.24.0+cu128\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.9.0+cu128\n","    Uninstalling torchaudio-2.9.0+cu128:\n","      Successfully uninstalled torchaudio-2.9.0+cu128\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.5 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.5 which is incompatible.\n","google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed anthropic-0.79.0 apache-tvm-ffi-0.1.8.post2 astor-0.8.1 blake3-1.0.8 cbor2-5.8.0 compressed-tensors-0.13.0 depyf-0.20.0 diskcache-5.6.3 dnspython-2.8.0 email-validator-2.3.0 fastapi-cli-0.0.23 fastapi-cloud-cli-0.13.0 fastar-0.8.0 flashinfer-python-0.6.1 gguf-0.17.1 grpcio-1.78.0 grpcio-reflection-1.78.0 huggingface-hub-0.36.2 ijson-3.4.0.post0 interegular-0.3.3 jmespath-1.1.0 lark-1.2.2 llguidance-1.3.0 llvmlite-0.44.0 lm-format-enforcer-0.11.3 loguru-0.7.3 mistral_common-1.9.1 model-hosting-container-standards-0.1.13 msgspec-0.20.0 ninja-1.13.0 numba-0.61.2 nvidia-cudnn-frontend-1.18.0 nvidia-cutlass-dsl-4.4.0 nvidia-cutlass-dsl-libs-base-4.4.0 openai-harmony-0.0.8 outlines_core-0.2.11 partial-json-parser-0.2.1.1.post7 prometheus-fastapi-instrumentator-7.1.0 protobuf-6.33.5 pybase64-1.4.3 pycountry-26.2.16 pydantic-extra-types-2.11.0 ray-2.53.0 rich-toolkit-0.19.4 rignore-0.7.6 setproctitle-1.3.7 setuptools-80.10.2 supervisor-4.3.0 torch-2.9.1 torchaudio-2.9.1 torchvision-0.24.1 transformers-4.57.6 triton-3.5.1 vllm-0.15.1 xgrammar-0.1.29\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","google","torch","torchgen","transformers","triton"]},"id":"29d14c2e48c14d22a26456dd37e204f0"}},"metadata":{}}],"source":["!pip install vllm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8201,"status":"ok","timestamp":1770905456187,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"mbpmn-UbZjjW","outputId":"126ad463-8dd6-4352-a765-bccf04f743a5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected', 'source'],\n","    num_rows: 61814\n","})"]},"metadata":{},"execution_count":1}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset('allenai/ultrafeedback_binarized_cleaned_train', split='train')\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Om9iiRvtoC_V"},"outputs":[],"source":["dataset = dataset.select(range(100))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1770904884120,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"KdklZHDHoZB8","outputId":"b0002fa4-86d2-475a-e210-23e6fb673b7a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               prompt  \\\n","72  Let's discuss a topic or concept that I'm curi...   \n","53  The input contains texts obtained from news ar...   \n","77  acording to (text from:https://www.prosci.com/...   \n","15  Instructions: In this task, you're given a fil...   \n","58  Traduire ceci en anglais: Q-NAVISTAR 19- Est-i...   \n","83  that you cannot make someone love you. All you...   \n","65  You are provided with an \"Event\", \"Intent\" rel...   \n","34  For the remainder of this session, prefer code...   \n","71                       what is kitty hawk known for   \n","56  Given a sentence in English, provide an equiva...   \n","8   Letters published for the first time today rev...   \n","47  Suppose you have the following words: rule, dr...   \n","60  Given the task definition and input, reply wit...   \n","18  In this task, you are given a sentence in eith...   \n","89  Create an article about the impact of self-ref...   \n","57  Please provide a comprehensive research propos...   \n","26  In the following task, you are given a yes/no ...   \n","51  1) The positive impact of patriotic symbolism ...   \n","95  In this task, you will be presented with a que...   \n","4   Write a gRPC server request interceptor that l...   \n","\n","                                            prompt_id  \\\n","72  721838f3dd310cd399f3b87374f4bda01d5f91b8efb651...   \n","53  72815128d461433e91d3bf8d28afd627a84d48a0a6333b...   \n","77  20cfad503953ef12128bf78b4c1f619d71cd154b84b1f6...   \n","15  37dc9b9ae18fcf56f5a1825fca2fd177a3f525f2b46b90...   \n","58  b41b2d245dda549c0ce6b2259a70dd648ee26fd28f43a3...   \n","83  c848a4bd1d774165005205fc0a75ad09e0960287349bf3...   \n","65  76c48f55ed456bc4b8e8a7474284a79e98d9098b59287c...   \n","34  c0f4b00f0882d34bdb91c77c81c4b7a1c4688786cff460...   \n","71  254abb06a17e68ee29310f8fcbef448c3a90eb67b48cec...   \n","56  434aa3bf1748cae239de9618705f1ae06d65853906136a...   \n","8   42d37b306e99a5f42c9c3310c320a737f3d3fb8dcc9bf8...   \n","47  d00e953c7dcfd9e466ab2c987512afc4417efdd5091fe2...   \n","60  9491f47c916ebce56a40bea76a37b39695e83c3969c9bb...   \n","18  ca53ad3901c5739f6af16718dec1214e0c685f349c5548...   \n","89  31acffe7b43741b86531ace42d722360f5cc290d3f1ce6...   \n","57  8c275b2f773ec083b990f252af74e39652ceaa13d482cf...   \n","26  b6d26afd49c4de907b1de491b04aae3dec0a7a6518bfc0...   \n","51  e24fcfe5e8e6843722246596768bcccfcf029395288865...   \n","95  dc11cb9ac348cb6d4ae7c69f090962798089b546baa8be...   \n","4   6ac490f83bad77756a95565cc5019ddc7ad9b3d2a8d8bd...   \n","\n","                                               chosen  \\\n","72  [{'content': 'Let's discuss a topic or concept...   \n","53  [{'content': 'The input contains texts obtaine...   \n","77  [{'content': 'acording to (text from:https://w...   \n","15  [{'content': 'Instructions: In this task, you'...   \n","58  [{'content': 'Traduire ceci en anglais: Q-NAVI...   \n","83  [{'content': 'that you cannot make someone lov...   \n","65  [{'content': 'You are provided with an \"Event\"...   \n","34  [{'content': 'For the remainder of this sessio...   \n","71  [{'content': 'what is kitty hawk known for', '...   \n","56  [{'content': 'Given a sentence in English, pro...   \n","8   [{'content': 'Letters published for the first ...   \n","47  [{'content': 'Suppose you have the following w...   \n","60  [{'content': 'Given the task definition and in...   \n","18  [{'content': 'In this task, you are given a se...   \n","89  [{'content': 'Create an article about the impa...   \n","57  [{'content': 'Please provide a comprehensive r...   \n","26  [{'content': 'In the following task, you are g...   \n","51  [{'content': '1) The positive impact of patrio...   \n","95  [{'content': 'In this task, you will be presen...   \n","4   [{'content': 'Write a gRPC server request inte...   \n","\n","                                             rejected  \\\n","72  [{'content': 'Let's discuss a topic or concept...   \n","53  [{'content': 'The input contains texts obtaine...   \n","77  [{'content': 'acording to (text from:https://w...   \n","15  [{'content': 'Instructions: In this task, you'...   \n","58  [{'content': 'Traduire ceci en anglais: Q-NAVI...   \n","83  [{'content': 'that you cannot make someone lov...   \n","65  [{'content': 'You are provided with an \"Event\"...   \n","34  [{'content': 'For the remainder of this sessio...   \n","71  [{'content': 'what is kitty hawk known for', '...   \n","56  [{'content': 'Given a sentence in English, pro...   \n","8   [{'content': 'Letters published for the first ...   \n","47  [{'content': 'Suppose you have the following w...   \n","60  [{'content': 'Given the task definition and in...   \n","18  [{'content': 'In this task, you are given a se...   \n","89  [{'content': 'Create an article about the impa...   \n","57  [{'content': 'Please provide a comprehensive r...   \n","26  [{'content': 'In the following task, you are g...   \n","51  [{'content': '1) The positive impact of patrio...   \n","95  [{'content': 'In this task, you will be presen...   \n","4   [{'content': 'Write a gRPC server request inte...   \n","\n","                                             messages  score_chosen  \\\n","72  [{'content': 'Let's discuss a topic or concept...           7.5   \n","53  [{'content': 'The input contains texts obtaine...          10.0   \n","77  [{'content': 'acording to (text from:https://w...           7.5   \n","15  [{'content': 'Instructions: In this task, you'...          10.0   \n","58  [{'content': 'Traduire ceci en anglais: Q-NAVI...           8.0   \n","83  [{'content': 'that you cannot make someone lov...           8.5   \n","65  [{'content': 'You are provided with an \"Event\"...           7.0   \n","34  [{'content': 'For the remainder of this sessio...           7.5   \n","71  [{'content': 'what is kitty hawk known for', '...           9.0   \n","56  [{'content': 'Given a sentence in English, pro...          10.0   \n","8   [{'content': 'Letters published for the first ...           8.5   \n","47  [{'content': 'Suppose you have the following w...           8.5   \n","60  [{'content': 'Given the task definition and in...           8.5   \n","18  [{'content': 'In this task, you are given a se...           8.0   \n","89  [{'content': 'Create an article about the impa...           8.0   \n","57  [{'content': 'Please provide a comprehensive r...           8.0   \n","26  [{'content': 'In the following task, you are g...           9.0   \n","51  [{'content': '1) The positive impact of patrio...           8.5   \n","95  [{'content': 'In this task, you will be presen...           7.5   \n","4   [{'content': 'Write a gRPC server request inte...           7.0   \n","\n","    score_rejected            source  \n","72             7.0          sharegpt  \n","53             5.0      flan_v2_niv2  \n","77             5.0          sharegpt  \n","15             6.0      flan_v2_niv2  \n","58             4.0          sharegpt  \n","83             6.0         ultrachat  \n","65             5.0      flan_v2_niv2  \n","34             3.0          sharegpt  \n","71             9.0          sharegpt  \n","56             4.0      flan_v2_niv2  \n","8              6.0  flan_v2_flan2021  \n","47             8.0     evol_instruct  \n","60             2.0      flan_v2_niv2  \n","18             2.0      flan_v2_niv2  \n","89             7.5         ultrachat  \n","57             7.5     evol_instruct  \n","26             8.5      flan_v2_niv2  \n","51             2.0         ultrachat  \n","95             2.0      flan_v2_niv2  \n","4              6.5          sharegpt  "],"text/html":["\n","  <div id=\"df-300264fa-1859-47d8-9c51-475b348e7bae\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>prompt_id</th>\n","      <th>chosen</th>\n","      <th>rejected</th>\n","      <th>messages</th>\n","      <th>score_chosen</th>\n","      <th>score_rejected</th>\n","      <th>source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>72</th>\n","      <td>Let's discuss a topic or concept that I'm curi...</td>\n","      <td>721838f3dd310cd399f3b87374f4bda01d5f91b8efb651...</td>\n","      <td>[{'content': 'Let's discuss a topic or concept...</td>\n","      <td>[{'content': 'Let's discuss a topic or concept...</td>\n","      <td>[{'content': 'Let's discuss a topic or concept...</td>\n","      <td>7.5</td>\n","      <td>7.0</td>\n","      <td>sharegpt</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>The input contains texts obtained from news ar...</td>\n","      <td>72815128d461433e91d3bf8d28afd627a84d48a0a6333b...</td>\n","      <td>[{'content': 'The input contains texts obtaine...</td>\n","      <td>[{'content': 'The input contains texts obtaine...</td>\n","      <td>[{'content': 'The input contains texts obtaine...</td>\n","      <td>10.0</td>\n","      <td>5.0</td>\n","      <td>flan_v2_niv2</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>acording to (text from:https://www.prosci.com/...</td>\n","      <td>20cfad503953ef12128bf78b4c1f619d71cd154b84b1f6...</td>\n","      <td>[{'content': 'acording to (text from:https://w...</td>\n","      <td>[{'content': 'acording to (text from:https://w...</td>\n","      <td>[{'content': 'acording to (text from:https://w...</td>\n","      <td>7.5</td>\n","      <td>5.0</td>\n","      <td>sharegpt</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Instructions: In this task, you're given a fil...</td>\n","      <td>37dc9b9ae18fcf56f5a1825fca2fd177a3f525f2b46b90...</td>\n","      <td>[{'content': 'Instructions: In this task, you'...</td>\n","      <td>[{'content': 'Instructions: In this task, you'...</td>\n","      <td>[{'content': 'Instructions: In this task, you'...</td>\n","      <td>10.0</td>\n","      <td>6.0</td>\n","      <td>flan_v2_niv2</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>Traduire ceci en anglais: Q-NAVISTAR 19- Est-i...</td>\n","      <td>b41b2d245dda549c0ce6b2259a70dd648ee26fd28f43a3...</td>\n","      <td>[{'content': 'Traduire ceci en anglais: Q-NAVI...</td>\n","      <td>[{'content': 'Traduire ceci en anglais: Q-NAVI...</td>\n","      <td>[{'content': 'Traduire ceci en anglais: Q-NAVI...</td>\n","      <td>8.0</td>\n","      <td>4.0</td>\n","      <td>sharegpt</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>that you cannot make someone love you. All you...</td>\n","      <td>c848a4bd1d774165005205fc0a75ad09e0960287349bf3...</td>\n","      <td>[{'content': 'that you cannot make someone lov...</td>\n","      <td>[{'content': 'that you cannot make someone lov...</td>\n","      <td>[{'content': 'that you cannot make someone lov...</td>\n","      <td>8.5</td>\n","      <td>6.0</td>\n","      <td>ultrachat</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>You are provided with an \"Event\", \"Intent\" rel...</td>\n","      <td>76c48f55ed456bc4b8e8a7474284a79e98d9098b59287c...</td>\n","      <td>[{'content': 'You are provided with an \"Event\"...</td>\n","      <td>[{'content': 'You are provided with an \"Event\"...</td>\n","      <td>[{'content': 'You are provided with an \"Event\"...</td>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>flan_v2_niv2</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>For the remainder of this session, prefer code...</td>\n","      <td>c0f4b00f0882d34bdb91c77c81c4b7a1c4688786cff460...</td>\n","      <td>[{'content': 'For the remainder of this sessio...</td>\n","      <td>[{'content': 'For the remainder of this sessio...</td>\n","      <td>[{'content': 'For the remainder of this sessio...</td>\n","      <td>7.5</td>\n","      <td>3.0</td>\n","      <td>sharegpt</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>what is kitty hawk known for</td>\n","      <td>254abb06a17e68ee29310f8fcbef448c3a90eb67b48cec...</td>\n","      <td>[{'content': 'what is kitty hawk known for', '...</td>\n","      <td>[{'content': 'what is kitty hawk known for', '...</td>\n","      <td>[{'content': 'what is kitty hawk known for', '...</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>sharegpt</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>Given a sentence in English, provide an equiva...</td>\n","      <td>434aa3bf1748cae239de9618705f1ae06d65853906136a...</td>\n","      <td>[{'content': 'Given a sentence in English, pro...</td>\n","      <td>[{'content': 'Given a sentence in English, pro...</td>\n","      <td>[{'content': 'Given a sentence in English, pro...</td>\n","      <td>10.0</td>\n","      <td>4.0</td>\n","      <td>flan_v2_niv2</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Letters published for the first time today rev...</td>\n","      <td>42d37b306e99a5f42c9c3310c320a737f3d3fb8dcc9bf8...</td>\n","      <td>[{'content': 'Letters published for the first ...</td>\n","      <td>[{'content': 'Letters published for the first ...</td>\n","      <td>[{'content': 'Letters published for the first ...</td>\n","      <td>8.5</td>\n","      <td>6.0</td>\n","      <td>flan_v2_flan2021</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>Suppose you have the following words: rule, dr...</td>\n","      <td>d00e953c7dcfd9e466ab2c987512afc4417efdd5091fe2...</td>\n","      <td>[{'content': 'Suppose you have the following w...</td>\n","      <td>[{'content': 'Suppose you have the following w...</td>\n","      <td>[{'content': 'Suppose you have the following w...</td>\n","      <td>8.5</td>\n","      <td>8.0</td>\n","      <td>evol_instruct</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>Given the task definition and input, reply wit...</td>\n","      <td>9491f47c916ebce56a40bea76a37b39695e83c3969c9bb...</td>\n","      <td>[{'content': 'Given the task definition and in...</td>\n","      <td>[{'content': 'Given the task definition and in...</td>\n","      <td>[{'content': 'Given the task definition and in...</td>\n","      <td>8.5</td>\n","      <td>2.0</td>\n","      <td>flan_v2_niv2</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>In this task, you are given a sentence in eith...</td>\n","      <td>ca53ad3901c5739f6af16718dec1214e0c685f349c5548...</td>\n","      <td>[{'content': 'In this task, you are given a se...</td>\n","      <td>[{'content': 'In this task, you are given a se...</td>\n","      <td>[{'content': 'In this task, you are given a se...</td>\n","      <td>8.0</td>\n","      <td>2.0</td>\n","      <td>flan_v2_niv2</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>Create an article about the impact of self-ref...</td>\n","      <td>31acffe7b43741b86531ace42d722360f5cc290d3f1ce6...</td>\n","      <td>[{'content': 'Create an article about the impa...</td>\n","      <td>[{'content': 'Create an article about the impa...</td>\n","      <td>[{'content': 'Create an article about the impa...</td>\n","      <td>8.0</td>\n","      <td>7.5</td>\n","      <td>ultrachat</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>Please provide a comprehensive research propos...</td>\n","      <td>8c275b2f773ec083b990f252af74e39652ceaa13d482cf...</td>\n","      <td>[{'content': 'Please provide a comprehensive r...</td>\n","      <td>[{'content': 'Please provide a comprehensive r...</td>\n","      <td>[{'content': 'Please provide a comprehensive r...</td>\n","      <td>8.0</td>\n","      <td>7.5</td>\n","      <td>evol_instruct</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>In the following task, you are given a yes/no ...</td>\n","      <td>b6d26afd49c4de907b1de491b04aae3dec0a7a6518bfc0...</td>\n","      <td>[{'content': 'In the following task, you are g...</td>\n","      <td>[{'content': 'In the following task, you are g...</td>\n","      <td>[{'content': 'In the following task, you are g...</td>\n","      <td>9.0</td>\n","      <td>8.5</td>\n","      <td>flan_v2_niv2</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>1) The positive impact of patriotic symbolism ...</td>\n","      <td>e24fcfe5e8e6843722246596768bcccfcf029395288865...</td>\n","      <td>[{'content': '1) The positive impact of patrio...</td>\n","      <td>[{'content': '1) The positive impact of patrio...</td>\n","      <td>[{'content': '1) The positive impact of patrio...</td>\n","      <td>8.5</td>\n","      <td>2.0</td>\n","      <td>ultrachat</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>In this task, you will be presented with a que...</td>\n","      <td>dc11cb9ac348cb6d4ae7c69f090962798089b546baa8be...</td>\n","      <td>[{'content': 'In this task, you will be presen...</td>\n","      <td>[{'content': 'In this task, you will be presen...</td>\n","      <td>[{'content': 'In this task, you will be presen...</td>\n","      <td>7.5</td>\n","      <td>2.0</td>\n","      <td>flan_v2_niv2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Write a gRPC server request interceptor that l...</td>\n","      <td>6ac490f83bad77756a95565cc5019ddc7ad9b3d2a8d8bd...</td>\n","      <td>[{'content': 'Write a gRPC server request inte...</td>\n","      <td>[{'content': 'Write a gRPC server request inte...</td>\n","      <td>[{'content': 'Write a gRPC server request inte...</td>\n","      <td>7.0</td>\n","      <td>6.5</td>\n","      <td>sharegpt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-300264fa-1859-47d8-9c51-475b348e7bae')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-300264fa-1859-47d8-9c51-475b348e7bae button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-300264fa-1859-47d8-9c51-475b348e7bae');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Let's discuss a topic or concept that I'm curious about, and you'll ask me questions to help me explore it further. We'll work together to build a deep understanding of the topic, and you'll provide feedback to help me identify any misconceptions or gaps in my understanding, sort of like the Feynman technique. We'll approach this with an open mind, and we'll be curious and inquisitive as we explore the topic.\\nI want you to keep in mind that you do also ask specific questions that will push my understanding of said topic, it doesn't matter if I'm not capable of answering cause my goal is to learn more and more. Let's begin.\",\n          \"1) The positive impact of patriotic symbolism and rhetoric in mobilizing support for the Civil Rights Movement\",\n          \"Please provide a comprehensive research proposal that includes a hypothesis for conducting experiments related to consumer behavior. The proposal should include a detailed description of the target consumer group, their demographics, psychographics, and any other relevant information. Additionally, the proposal should specify the research methodology, including the sampling technique, data collection methods, and statistical analysis tools to be used. Furthermore, the proposal should outline the experimental design, including the independent and dependent variables, control variables, and any potential confounding variables. Finally, the proposal should discuss the potential ethical considerations and limitations of the study, as well as its practical implications for the field of consumer behavior. Please ensure that the hypothesis is specific, testable, and grounded in existing literature on consumer behavior.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"721838f3dd310cd399f3b87374f4bda01d5f91b8efb651e5069d9f94115ae5bf\",\n          \"e24fcfe5e8e6843722246596768bcccfcf029395288865ac5867aa93839702b5\",\n          \"8c275b2f773ec083b990f252af74e39652ceaa13d482cf6f7a78e0f0354271a2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chosen\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rejected\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"messages\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_chosen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9215975831474158,\n        \"min\": 7.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          7.5,\n          10.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_rejected\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.284962282309918,\n        \"min\": 2.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          9.0,\n          7.0,\n          8.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"flan_v2_niv2\",\n          \"evol_instruct\",\n          \"ultrachat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}],"source":["df = pd.DataFrame(ds.to_pandas())\n","df.sample(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1770904884135,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"9UlYw-Xvj6Uz","outputId":"dd608dc0-20ee-49fb-cd67-ec18548a35a2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 8)"]},"metadata":{},"execution_count":10}],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1770904884143,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"zSV_5xMUfsGa","outputId":"5c4a9dd1-a100-4501-9596-0b4c1ac39133"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([{'content': 'Write a 1,000-word op-ed piece in a formal tone, analyzing and providing examples of the ways in which social media platforms have been utilized to spread extremist and violent ideologies. In your analysis, discuss the specific tactics that these groups use to spread their messages online and the effects of these tactics on both individuals and society. Additionally, provide possible solutions that could be implemented to combat the spread of these dangerous ideologies on social media. Your piece should be well-researched, citing reputable sources to support your arguments.', 'role': 'user'},\n","       {'content': \"Title: The Noxious Alliance of Social Media and Extremism: A Threat to Human Progress\\n\\nThe advent of social media platforms has irrevocably revolutionized the way we communicate, share and consume information. While these platforms provide access to information for a global audience and allow individuals to connect regardless of geographical barriers, they have also become a breeding ground for the spread of extremist and violent ideologies, presenting a significant threat to human progress. The pervasiveness of social media, coupled with the anonymity afforded by these platforms, has made it easier for extremists to disseminate their messages, recruit new members, and incite violence against targeted groups, resulting in devastating consequences.\\n\\nExtremist groups often exploit the viral nature of social media to propagate their ideologies. Fast-paced videos, catchy slogans, and emotionally-charged content are a few of the strategies employed by these groups. Swift and aggressive tactics are used to capture the attention of the audience and to stir emotions, especially fear, anger, and hatred. The dissemination of misinformation and conspiracy theories facilitates the spread of extremist ideologies as they exploit the breakdown of trust in traditional media sources. Social media algorithms, designed to show users content that they are likely to engage with, can inadvertently promote more extreme content, further exacerbating visibility.\\n\\nThe Rohingya crisis in Myanmar provides a striking example of the harmful effects of social media promotion on extremism. In 2017, a blitz of Facebook posts filled with false information portrayed the Rohingya, a Muslim minority, as a threat to the predominantly Buddhist country. These posts, often containing graphic images and victim-blaming narratives, led to real-world violence, displacement, and genocide. As noted by the United Nations, social media played a “determining role” in creating hostility towards the Rohingya.\\n\\nThe influence of extremist groups on social media goes beyond victims in the immediate affected region. The diffusion of extremist ideologies online can impact anyone, regardless of geography. Individuals can be targeted and recruited into groups, potentially leading to real-world violence or radicalization. This phenomenon has been observed internationally, from the rise of extremist attacks across Europe to the influence of white supremacist groups in the United States.\\n\\nRadicalization can start with something as innocuous as an online discussion or the sharing of a controversial thread. Individuals vulnerable to extremist ideologies, often seeking answers or meaning in a rapidly changing world, can be drawn into the narratives presented by extremist groups. This further perpetuates social divisions and increases polarization, making it difficult to engage in productive dialogue and find solutions for societal issues.\\n\\nThe fight against the spread of extremist ideologies on social media requires a multifaceted approach, incorporating both technical and policy measures:\\n\\n1. Social Media Platforms' Responsibility: There should be a significant increase in monitoring and regulation by these platforms. Strict policies need to be enforced to prevent the spread of fake news, hate speech, and incitement to violence. Platforms should provide easy mechanisms for users to report harmful content, ensuring swift action in response.\\n\\n2. Education and Awareness: Individuals must be made aware of the tactics used by extremist groups on social media. This can be achieved through educational initiatives in schools and communities that teach about critical thinking, media literacy, and the promotion of respectful discourse.\\n\\n3. Counter-Narratives: Effective counter-narratives that challenge the extremist narratives should be encouraged and shared on these platforms. This can include sharing positive stories of diversity, resilience, and inclusion, showcasing the beauty of global humanity, and aggressively promoting fact-based content.\\n\\n4. Collaboration: Governments, civil society organizations, and tech giants should work together to combat this issue. Governments should enact and enforce laws to prevent the promotion of extremist ideologies online, while tech giants need to take investment, to design more effective algorithms that prioritize content promoting healthy social interactions and factual accuracy.\\n\\n5. Encourage Technology to Fight Extremism: The use of Artificial Intelligence and Machine Learning technologies can be instrumental in detecting and removing harmful content. These systems can analyze patterns in online discourse, flag content worthy of review, and even predict extreme behaviors before they escalate into violent actions.\", 'role': 'assistant'}],\n","      dtype=object)"]},"metadata":{},"execution_count":11}],"source":["df.iloc[0]['chosen']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1770901687911,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"qfdpUCy6fwNK","outputId":"6285465f-ab72-4e08-e211-b2dd5e8288ee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["prompt            Write a 1,000-word op-ed piece in a formal ton...\n","prompt_id         de53359961ee872f552ac945d42f1017a2f0d55b0bb08d...\n","chosen            [{'content': 'Write a 1,000-word op-ed piece i...\n","rejected          [{'content': 'Write a 1,000-word op-ed piece i...\n","messages          [{'content': 'Write a 1,000-word op-ed piece i...\n","score_chosen                                                    7.0\n","score_rejected                                                  6.0\n","source                                                    ultrachat\n","Name: 0, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>prompt</th>\n","      <td>Write a 1,000-word op-ed piece in a formal ton...</td>\n","    </tr>\n","    <tr>\n","      <th>prompt_id</th>\n","      <td>de53359961ee872f552ac945d42f1017a2f0d55b0bb08d...</td>\n","    </tr>\n","    <tr>\n","      <th>chosen</th>\n","      <td>[{'content': 'Write a 1,000-word op-ed piece i...</td>\n","    </tr>\n","    <tr>\n","      <th>rejected</th>\n","      <td>[{'content': 'Write a 1,000-word op-ed piece i...</td>\n","    </tr>\n","    <tr>\n","      <th>messages</th>\n","      <td>[{'content': 'Write a 1,000-word op-ed piece i...</td>\n","    </tr>\n","    <tr>\n","      <th>score_chosen</th>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>score_rejected</th>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>source</th>\n","      <td>ultrachat</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":12}],"source":["df.iloc[0]"]},{"cell_type":"code","source":[],"metadata":{"id":"kBrhA3vzYqlG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60911,"status":"ok","timestamp":1770903120224,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"1L6eaeYFmo65","outputId":"b477e363-746c-4141-e6a8-55b5b6625725"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO 02-12 13:31:00 [utils.py:261] non-default args: {'tokenizer': '/content/drive/MyDrive/1 - projects/cs/mini_instruct_gpt/saved_models/deepseek_sft_final/', 'trust_remote_code': True, 'dtype': 'float16', 'max_model_len': 8192, 'gpu_memory_utilization': 0.8, 'max_num_batched_tokens': 2048, 'max_num_seqs': 2, 'disable_log_stats': True, 'model': '/content/drive/MyDrive/1 - projects/cs/mini_instruct_gpt/saved_models/deepseek_sft_final/'}\n"]},{"output_type":"stream","name":"stderr","text":["The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n","The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"]},{"output_type":"stream","name":"stdout","text":["INFO 02-12 13:31:00 [model.py:541] Resolved architecture: Qwen2ForCausalLM\n","INFO 02-12 13:31:00 [model.py:1561] Using max model len 8192\n","INFO 02-12 13:31:00 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=2048.\n","INFO 02-12 13:32:01 [llm.py:343] Supported tasks: ['generate']\n"]},{"output_type":"execute_result","data":{"text/plain":["Qwen2ForCausalLM()(\n","  (model): Qwen2Model()(\n","    (embed_tokens): VocabParallelEmbedding(num_embeddings=151936, embedding_dim=1536, org_vocab_size=151936, num_embeddings_padded=151936, tp_size=1)\n","    (layers): ModuleList()(\n","      (0-27): 28 x Qwen2DecoderLayer()(\n","        (self_attn): Qwen2Attention()(\n","          (qkv_proj): QKVParallelLinear(in_features=1536, output_features=2048, bias=True, tp_size=1, gather_output=False)\n","          (o_proj): RowParallelLinear(in_features=1536, output_features=1536, bias=False, tp_size=1, reduce_results=True)\n","          (rotary_emb): RotaryEmbedding(head_size=128, rotary_dim=128, max_position_embeddings=131072, base=10000, is_neox_style=True)(\n","            (apply_rotary_emb): ApplyRotaryEmb(is_neox_style=True, enable_fp32_compute=False)\n","          )\n","          (attn): Attention(head_size=128, num_heads=12, num_kv_heads=2, scale=0.08838834764831845, backend=FlashInferImpl)\n","        )\n","        (mlp): Qwen2MLP()(\n","          (gate_up_proj): MergedColumnParallelLinear(in_features=1536, output_features=17920, bias=False, tp_size=1, gather_output=False)\n","          (down_proj): RowParallelLinear(in_features=8960, output_features=1536, bias=False, tp_size=1, reduce_results=True)\n","          (act_fn): SiluAndMul()\n","        )\n","        (input_layernorm): RMSNorm(hidden_size=1536, eps=1e-06)\n","        (post_attention_layernorm): RMSNorm(hidden_size=1536, eps=1e-06)\n","      )\n","    )\n","    (norm): RMSNorm(hidden_size=1536, eps=1e-06)\n","  )\n","  (lm_head): ParallelLMHead(num_embeddings=151936, embedding_dim=1536, org_vocab_size=151936, num_embeddings_padded=151936, tp_size=1)\n","  (logits_processor): LogitsProcessor(vocab_size=151936, org_vocab_size=151936, scale=1.0, logits_as_input=False)\n",")"]},"metadata":{},"execution_count":32}],"source":["from vllm import LLM\n","\n","llm = LLM(\n","    model=save_dir,\n","    tokenizer=save_dir,             # optional; defaults to model path\n","    tensor_parallel_size=1,\n","    trust_remote_code=True,          # sometimes needed depending on model\n","    max_model_len=8192,          # try 4096 first if it still fails\n","    max_num_batched_tokens=2048, # smaller = less memory pressure\n","    max_num_seqs=2,              # keep concurrency low on T4\n","    gpu_memory_utilization=0.80, # KV cache budget control\n","    dtype=\"float16\",\n",")\n","llm"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":544,"status":"ok","timestamp":1770903120770,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"},"user_tz":-210},"id":"LaaL1L02zgQR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70aa0e39-75c4-4966-c416-f3e388741b8b"},"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer you are loading from '/content/drive/MyDrive/1 - projects/cs/mini_instruct_gpt/saved_models/deepseek_sft_final/' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"]},{"output_type":"execute_result","data":{"text/plain":["LlamaTokenizerFast(name_or_path='/content/drive/MyDrive/1 - projects/cs/mini_instruct_gpt/saved_models/deepseek_sft_final/', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n","\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n","}\n",")"]},"metadata":{},"execution_count":33}],"source":["tokenizer = AutoTokenizer.from_pretrained(save_dir)\n","tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ps7UwxnMpGwV"},"outputs":[],"source":["def get_msg(instruction):\n","  message = [\n","      {'role': 'user', 'content': instruction}\n","  ]\n","\n","  return message\n","\n","prompts = [\n","    tokenizer.apply_chat_template(get_msg(row['prompt']), tokenize=False, add_generation_prompt=True)\n","    for row in ds\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SnIlYsxDzIjf","colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1770903120931,"user_tz":-210,"elapsed":23,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}},"outputId":"618ac595-c9d6-437b-990b-8fab4f56f5fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<｜begin▁of▁sentence｜><｜User｜>Write a 1,000-word op-ed piece in a formal tone, analyzing and providing examples of the ways in which social media platforms have been utilized to spread extremist and violent ideologies. In your analysis, discuss the specific tactics that these groups use to spread their messages online and the effects of these tactics on both individuals and society. Additionally, provide possible solutions that could be implemented to combat the spread of these dangerous ideologies on social media. Your piece should be well-researched, citing reputable sources to support your arguments.<｜Assistant｜><think>\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}],"source":["prompts[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygf2ZbW0xtwZ","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1770903120940,"user_tz":-210,"elapsed":7,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}},"outputId":"1f992ead-4bb3-4788-ad0c-668f94c0c8d9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Write a 1,000-word op-ed piece in a formal tone, analyzing and providing examples of the ways in which social media platforms have been utilized to spread extremist and violent ideologies. In your analysis, discuss the specific tactics that these groups use to spread their messages online and the effects of these tactics on both individuals and society. Additionally, provide possible solutions that could be implemented to combat the spread of these dangerous ideologies on social media. Your piece should be well-researched, citing reputable sources to support your arguments.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}],"source":["df.iloc[0]['prompt']"]},{"cell_type":"code","source":[],"metadata":{"id":"XK-slXUAKxlK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"RdvM-7Q6m0Wv","executionInfo":{"status":"ok","timestamp":1771343244257,"user_tz":-210,"elapsed":5403,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}}},"outputs":[],"source":["from datasets import Dataset\n","\n","\n","load_saved_ds = True\n","ds_path = '/content/drive/MyDrive/1 - projects/cs/mini_instruct_gpt/dolly15k-train_with_responses.csv'\n","\n","if load_saved_ds:\n","  dataset = Dataset.from_csv(ds_path)\n","\n","else:\n","  from vllm import SamplingParams\n","  N_RESPONSES = 1\n","\n","  for p in range(N_RESPONSES):\n","    sampling_params = SamplingParams(\n","          temperature=0.8,\n","          top_p=0.9,\n","          max_tokens=2048,\n","          seed=p * 50,\n","    )\n","\n","    response = llm.generate(prompts, sampling_params)\n","    output = list(map(lambda x: x.outputs[0].text, response))\n","    dataset = dataset.add_column(f'response_{p}', output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z32X7wNMYyHQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jBFZ3ITNOinO"},"source":["#Part 2: Reward Model Inference"]},{"cell_type":"code","source":["import shutil\n","import os\n","\n","# Clear the corrupted cache\n","cache_dir = os.path.expanduser(\"~/.cache/huggingface/modules\")\n","if os.path.exists(cache_dir):\n","    shutil.rmtree(cache_dir)\n","    print(f\"Cleared: {cache_dir}\")\n","\n","# Also clear the transformers cache\n","cache_dir2 = os.path.expanduser(\"~/.cache/huggingface/hub\")\n","if os.path.exists(cache_dir2):\n","    shutil.rmtree(cache_dir2)\n","    print(f\"Cleared: {cache_dir2}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uq4ofmHrb7iA","executionInfo":{"status":"ok","timestamp":1771345789767,"user_tz":-210,"elapsed":1009,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}},"outputId":"6c8ef4d5-a590-4be1-b8b8-65f19428b796"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleared: /root/.cache/huggingface/modules\n","Cleared: /root/.cache/huggingface/hub\n"]}]},{"cell_type":"code","source":["!pip install -U bitsandbytes\n","!pip install transformers==4.36.2"],"metadata":{"id":"dNP_fbWgM6Vy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771343238857,"user_tz":-210,"elapsed":29759,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}},"outputId":"b61b5e97-bd92-40c4-aedd-4a90984b14a1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.2)\n","Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.3)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (80.10.2)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","bnb_config"],"metadata":{"id":"hytqngbjM1Y3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771347277691,"user_tz":-210,"elapsed":42,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}},"outputId":"50855285-e000-412f-ea6a-c41003627240"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BitsAndBytesConfig {\n","  \"bnb_4bit_compute_dtype\": \"float16\",\n","  \"bnb_4bit_quant_type\": \"fp4\",\n","  \"bnb_4bit_use_double_quant\": true,\n","  \"llm_int8_enable_fp32_cpu_offload\": false,\n","  \"llm_int8_has_fp16_weight\": false,\n","  \"llm_int8_skip_modules\": null,\n","  \"llm_int8_threshold\": 6.0,\n","  \"load_in_4bit\": true,\n","  \"load_in_8bit\": false,\n","  \"quant_method\": \"bitsandbytes\"\n","}"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","from typing import List, Literal, Optional, Tuple, Union, Dict\n","\n","class ArmoRMPipeline:\n","    def __init__(self, model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, truncation=True, trust_remote_code=False, max_length=4096):\n","        self.model = AutoModelForSequenceClassification.from_pretrained(\n","            model_id,\n","            device_map=\"cuda\",\n","            trust_remote_code=trust_remote_code,\n","            torch_dtype=torch_dtype,\n","            # quantization_config=bnb_config,\n","        ).cuda()  # Manually move to GPU after loading\n","        self.tokenizer = AutoTokenizer.from_pretrained(\n","            model_id,\n","            use_fast=True,\n","        )\n","        self.truncation = truncation\n","        self.device = self.model.device\n","        self.max_length = max_length\n","\n","    def __call__(self, messages: List[Dict[str, str]]) -> Dict[str, float]:\n","        input_ids = self.tokenizer.apply_chat_template(\n","            messages,\n","            return_tensors=\"pt\",\n","            padding=True,\n","            truncation=self.truncation,\n","            max_length=self.max_length,\n","        ).to(self.device)\n","        with torch.no_grad():\n","            output = self.model(input_ids)\n","            score = output.score.float().item()\n","        return score"],"metadata":{"id":"TS-lX4dMZzZe","executionInfo":{"status":"ok","timestamp":1771347794896,"user_tz":-210,"elapsed":40,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NMMAvZflOep3","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["0bcc3d8cefc14a3cb99269001d9b2b82","29787577b3044f85947d4db7a7356e43","0937af9c5d4a4685a688a310a843edb8","3d2ab7e07e104737889b6c3b3ec52a07","92731b43f3a6408693df4f211bfa73de","94265678c6814db78b5605ac75880f68","90ff4ae12fec4dcf9abbba5b71ca792b","6a0f3f6cd2164a77811deba17994c0a6","153a70b03b0b4408b20719f2c5e941c8","0c1bdceb4e3543d4b2fb07dce8aed94d","7034869ee2cb4b6389126be6a27c7df6"]},"outputId":"e6c578a5-35ab-447d-f7c3-8f2eb2d41bf3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bcc3d8cefc14a3cb99269001d9b2b82"}},"metadata":{}}],"source":["from transformers import pipeline\n","\n","rm = ArmoRMPipeline(\n","    \"RLHFlow/ArmoRM-Llama3-8B-v0.1\",\n","    trust_remote_code=False\n","    )\n","\n","rm"]},{"cell_type":"code","source":["from vllm import SamplingParams\n","\n","def get_msg(instruction, response):\n","  return [\n","      {'role': 'user', 'content': instruction},\n","      {'role': 'assistant', 'content': response},\n","          ]\n","\n","\n","\n","N_RESPONSES = 1\n","rewards = {}\n","\n","for i in range(N_RESPONSES):\n","  rewards[f'response_{i}_rewards'] = []\n","\n","  for row in dataset:\n","    m = get_msg(row['prompt'], row[f'response_{i}'])\n","    reward = rm(m)\n","    rewards[f'response_{i}_rewards'].append(reward)"],"metadata":{"id":"1iLon3azVUeC","executionInfo":{"status":"aborted","timestamp":1771346716908,"user_tz":-210,"elapsed":45476,"user":{"displayName":"Hossein Soltani","userId":"08889536537254151863"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k, v in rewards.items():\n","  dataset = dataset.add_column(k, v)"],"metadata":{"id":"nUEiDaEAGDpY"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"094d4517e6b244f98736e8feb88230af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d1a87b833614436847d35bda9e9157f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef5560a9b06d422990789f3788a23394","IPY_MODEL_28838959fca34f73aa99c4d2754a4e2d","IPY_MODEL_1e1f534b21fe4ccaafc68d032562b71d"],"layout":"IPY_MODEL_669465d07d614792b43f34777b9649a8"}},"0d43a765a0f6445b9a065889ab09a1a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e1f534b21fe4ccaafc68d032562b71d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b86b2f87816a45c896addff477b1320c","placeholder":"​","style":"IPY_MODEL_094d4517e6b244f98736e8feb88230af","value":" 100/100 [00:00&lt;00:00, 1060.04 examples/s]"}},"28838959fca34f73aa99c4d2754a4e2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df8ce1a1df394233a2c7b16a14d57233","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d43a765a0f6445b9a065889ab09a1a6","value":100}},"3fb46da2a97f456b97607060759c2637":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49fdeee913764ff0adf617b09d555e0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"669465d07d614792b43f34777b9649a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b86b2f87816a45c896addff477b1320c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df8ce1a1df394233a2c7b16a14d57233":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef5560a9b06d422990789f3788a23394":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fb46da2a97f456b97607060759c2637","placeholder":"​","style":"IPY_MODEL_49fdeee913764ff0adf617b09d555e0b","value":"Map: 100%"}},"faaf369ee75c4e5fbecf776d4bb5612a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b357e58935e4a879f71ffad94ebb24b","IPY_MODEL_300e3b6cb0b649f595602bd2237719ab","IPY_MODEL_a69c56d4f1f84874845fcfec528351e9"],"layout":"IPY_MODEL_5193304123c24e828ada8829bfc4c4a6"}},"1b357e58935e4a879f71ffad94ebb24b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62468c85ec8445a89a392b11529ae32d","placeholder":"​","style":"IPY_MODEL_b92fb6a911494e249d7f3986a3eb6cd1","value":"Map: 100%"}},"300e3b6cb0b649f595602bd2237719ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb6974a035144bccb16557be7369f6e8","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3983f748ae841e7b377742f24b9b42a","value":100}},"a69c56d4f1f84874845fcfec528351e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd38f1f478034e86a8d64975f215b686","placeholder":"​","style":"IPY_MODEL_5085d624b47d43d6b815bd8e9362d280","value":" 100/100 [00:00&lt;00:00, 3546.92 examples/s]"}},"5193304123c24e828ada8829bfc4c4a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62468c85ec8445a89a392b11529ae32d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92fb6a911494e249d7f3986a3eb6cd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb6974a035144bccb16557be7369f6e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3983f748ae841e7b377742f24b9b42a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd38f1f478034e86a8d64975f215b686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5085d624b47d43d6b815bd8e9362d280":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bcc3d8cefc14a3cb99269001d9b2b82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29787577b3044f85947d4db7a7356e43","IPY_MODEL_0937af9c5d4a4685a688a310a843edb8","IPY_MODEL_3d2ab7e07e104737889b6c3b3ec52a07"],"layout":"IPY_MODEL_92731b43f3a6408693df4f211bfa73de"}},"29787577b3044f85947d4db7a7356e43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94265678c6814db78b5605ac75880f68","placeholder":"​","style":"IPY_MODEL_90ff4ae12fec4dcf9abbba5b71ca792b","value":"Loading checkpoint shards:  25%"}},"0937af9c5d4a4685a688a310a843edb8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a0f3f6cd2164a77811deba17994c0a6","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_153a70b03b0b4408b20719f2c5e941c8","value":1}},"3d2ab7e07e104737889b6c3b3ec52a07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c1bdceb4e3543d4b2fb07dce8aed94d","placeholder":"​","style":"IPY_MODEL_7034869ee2cb4b6389126be6a27c7df6","value":" 1/4 [00:13&lt;00:39, 13.07s/it]"}},"92731b43f3a6408693df4f211bfa73de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94265678c6814db78b5605ac75880f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90ff4ae12fec4dcf9abbba5b71ca792b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a0f3f6cd2164a77811deba17994c0a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"153a70b03b0b4408b20719f2c5e941c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c1bdceb4e3543d4b2fb07dce8aed94d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7034869ee2cb4b6389126be6a27c7df6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}